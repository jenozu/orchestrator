# MCP Server Setup Guide

## âœ… Status: READY TO USE

Your MCP Codegen server is now fully configured and ready to use!

## What Was Fixed

1. âœ… **Import Path Fixed**: `scripts/run_mcp_server.py` now correctly adds the project root to Python path
2. âœ… **Environment Variables**: The `.env` file is automatically loaded with your OpenAI API key
3. âœ… **MCP Configuration**: `merged_mcp_config.json` updated to use the fixed script

## How to Use the MCP Server

### Option 1: Use in Cursor (Recommended)

The MCP server integrates directly into Cursor via the MCP protocol. To enable it:

1. **Copy the configuration** from `merged_mcp_config.json` (specifically the `codegen` section)
2. **Add it to Cursor's MCP settings**:
   - On Windows: `%APPDATA%\Cursor\User\globalStorage\rooveterinaryinc.roo-cline\settings\cline_mcp_settings.json`
   - Or use Cursor's Settings UI

3. **Restart Cursor** to load the MCP server

4. **Use the tools** in your AI conversations:
   - `create_prd` - Create Product Requirements Documents
   - `parse_prd` - Parse PRD files into structured requirements
   - `retrieve_context` - Search your knowledge base with RAG
   - `generate_project` - Generate complete projects from requirements
   - `debug_error` - Debug code with learning memory
   - `search_learned_solutions` - Find previously learned solutions
   - `get_learning_stats` - View learning statistics

### Option 2: Test the Server Directly

You can test if the server starts correctly:

```powershell
# This should run without errors and initialize the learning system
python scripts/run_mcp_server.py
```

**Expected behavior**: The server initializes and completes immediately (this is normal for stdio-based MCP servers).

### Option 3: Use with Claude Desktop

Add this to Claude Desktop's MCP configuration:

```json
{
  "mcpServers": {
    "codegen": {
      "command": "python",
      "args": [
        "scripts/run_mcp_server.py"
      ],
      "cwd": "C:\\Users\\andel\\Desktop\\orchestrator"
    }
  }
}
```

## Available Tools

### 1. **create_prd**
Create a Product Requirements Document from an idea.

**Parameters:**
- `idea` (required): The product idea description
- `output_path` (optional): Where to save the PRD (default: `docs/generated_prd.md`)

### 2. **parse_prd**
Parse a PRD or README into structured requirements.

**Parameters:**
- `document_path` (required): Path to the document to parse

### 3. **retrieve_context**
Retrieve similar code patterns from your knowledge base using RAG.

**Parameters:**
- `query` (required): What you're looking for
- `k` (optional): Number of results to return (default: 5)

### 4. **generate_project**
Generate a complete project from structured requirements.

**Parameters:**
- `requirements` (required): Structured requirements object
- `output_dir` (required): Where to generate the project

### 5. **debug_error**
Analyze errors and propose fixes, with learning from past solutions.

**Parameters:**
- `code` (required): The code that has the error
- `error` (required): The error message
- `context` (optional): Additional context about the error

### 6. **search_learned_solutions**
Search for previously learned solutions to similar problems.

**Parameters:**
- `query` (required): Description of the problem
- `category` (optional): Solution category (default: `error_fixes`)
- `limit` (optional): Number of results (default: 5)

### 7. **get_learning_stats**
Get statistics about what the system has learned.

**Parameters:**
- `category` (optional): Stats category (default: `error_fixes`)

## Architecture

```
scripts/run_mcp_server.py
    â†“
mcp_codegen/server.py  (loads .env)
    â†“
â”œâ”€â”€ tools/
â”‚   â”œâ”€â”€ prd_tool.py        (Create PRDs)
â”‚   â”œâ”€â”€ parser_tool.py     (Parse documents)
â”‚   â”œâ”€â”€ rag_tool.py        (RAG retrieval)
â”‚   â”œâ”€â”€ generator_tool.py  (Generate code)
â”‚   â””â”€â”€ debugger_tool.py   (Debug with learning)
â””â”€â”€ agents/
    â””â”€â”€ learning_memory.py (Learning system)
```

## Troubleshooting

### Error: "No module named 'mcp_codegen'"
- **Fixed!** The script now automatically adds the project root to Python path

### Warning about LangChain Beta
- This is just informational - the learning system is working correctly
- The warning is about the `init_embeddings` function in the learning memory

### Server completes immediately
- This is **expected behavior** for stdio-based MCP servers
- They only stay running when connected to an MCP client (Cursor/Claude Desktop)

## Testing the Full System

To test the orchestrator (which uses all the agents):

```powershell
python agents/orchestrator.py
```

This will:
- Load your `.env` file automatically
- Use your OpenAI API key
- Run the full agent system with RAG and learning

## Next Steps

1. âœ… **MCP Server is ready** - Configure it in Cursor or Claude Desktop
2. âœ… **Environment variables work** - All agents automatically load from `.env`
3. âœ… **Learning system active** - Your system learns from every debug session
4. âœ… **RAG enabled** - Access your entire knowledge base

You're all set! ðŸš€

